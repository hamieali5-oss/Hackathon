ğŸ“˜ README.md â€” GeoHackathon 2025 â€” Subchallenge 1
ğŸ›¢ï¸ GeoHackathon 2025 â€” Subchallenge 1
RAG-based Summarization of Well Reports (Improved Solution)

CPUâ€“only â€¢ Open-source LLM â€¢ ChromaDB â€¢ Sentence-Transformers â€¢ LangChain

ğŸ“Œ Obiettivo

Produrre un riassunto tecnico (â‰¤ N parole) di un report PDF (NLOG style),
utilizzando una pipeline Retrieval-Augmented Generation (RAG):

Indicizzazione PDF â†’ chunking â†’ embeddings â†’ ChromaDB

Recupero dei chunk rilevanti

Prompt engineering controllato per evitare allucinazioni

Generazione del summary tramite google/flan-t5-base (CPU-only)

Output finale con citazioni (file + pagina)

La soluzione rispetta tutte le linee guida del GeoHackathon.

ğŸ“‚ Struttura del progetto
geohack_sub1/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ cli.py
    â”œâ”€â”€ ingest.py
    â”œâ”€â”€ splitter.py
    â”œâ”€â”€ embeddings.py
    â”œâ”€â”€ vectorstore.py
    â”œâ”€â”€ rag_chain.py
    â”œâ”€â”€ summary.py
    â””â”€â”€ utils.py  (opzionale)

ğŸ”§ Installazione

Attiva una virtualenv (Windows/Mac/Linux):

python -m venv .venv
source .venv/bin/activate       # Windows: .venv\Scripts\activate
pip install -r requirements.txt

ğŸ“¥ 1) Inserisci i PDF

Metti tutti i file PDF nella cartella:

data/raw/


Crea la cartella se non esiste:

mkdir -p data/raw

ğŸ§± 2) Costruisci lâ€™indice RAG (ChromaDB)
python -m src.cli index --docs data/raw --index data/index


Parametri opzionali:

--chunk-size (default 800)

--chunk-overlap (default 120)

Lâ€™indice verrÃ  creato in:

data/index/

ğŸ“ 3) Ottieni un riassunto tecnico (â‰¤ N parole) con citazioni

Esempio:

python -m src.cli summarize \
    --doc data/raw/WellReport-12.pdf \
    --index data/index \
    --words 200 \
    --k 20


Output:

Riassunto (stampato a schermo)

Citazioni (file + pagina)

File JSON salvato automaticamente:

data/index/WellReport-12.summary.json

ğŸ” 4) Debug: vedere i chunk recuperati dal sistema
python -m src.cli preview \
    --index data/index \
    --query "completion and well test data" \
    --k 5

ğŸ¤– Dettagli tecnici della pipeline
ğŸ”¹ Embeddings

sentence-transformers/all-MiniLM-L6-v2 (CPU-friendly, 384-d)

ğŸ”¹ Vector Store

ChromaDB persistente su disco

ğŸ”¹ Retriever

Semantic search

Over-retrieval (k * 3)

Filtro preferenziale dei chunk appartenenti al PDF target

ğŸ”¹ LLM

google/flan-t5-base

Pipeline HuggingFace Transformers

CPU-only

ğŸ”¹ Prompt di generazione

Caratteristiche:

â€œAnswer from context onlyâ€

Word limit rigoroso

Zero allucinazioni

Preserva dati numerici (depth, pressure, rates)

ğŸ§ª Esempio di comando completo
python -m src.cli summarize \
    --doc data/raw/NLOG-Report-05.pdf \
    --index data/index \
    --words 180 \
    --k 24 \
    --query "well completion, testing data, reservoir, production overview"

ğŸŸ¦ CompatibilitÃ 

Python 3.9+

CPU-only

Testato su Windows 10, Ubuntu 22, macOS M1 (emulazione CPU)

ğŸ Stato del progetto

âœ” Subchallenge 1 completata (RAG + summary + citations)

â³ Subchallenge 2 â€” extraction pipeline (verrÃ  integrata)

â³ Subchallenge 3 â€” nodal analysis + agent system (verrÃ  integrata)
